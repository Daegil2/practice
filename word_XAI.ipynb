{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train/train_data.csv')\n",
    "test=pd.read_csv('test/test_data.csv')\n",
    "submission= pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_dir= 'train/'\n",
    "test_file_dir='test/'\n",
    "x_train= np.zeros((len(train),28,28,1))\n",
    "y_train= train['label']\n",
    "# 데이터 저장할 공간 생성\n",
    "x_test = np.zeros((len(test), 28,28,1))\n",
    "\n",
    "for i, image_name in enumerate(train['file_name']):\n",
    "    x_train[i] = np.reshape(np.array(Image.open(train_file_dir + image_name)),(28,28,1))\n",
    "\n",
    "for i, image_name in enumerate(test['file_name']):\n",
    "    x_test[i] = np.reshape(np.array(Image.open(test_file_dir + image_name)), (28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x_train, y_train, test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(x_train, y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 0.6498 - accuracy: 0.8533 - val_loss: 0.1778 - val_accuracy: 0.9460\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0877 - accuracy: 0.9711 - val_loss: 0.1368 - val_accuracy: 0.9640\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.1573 - val_accuracy: 0.9620\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.1006 - val_accuracy: 0.9700\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.1100 - val_accuracy: 0.9800\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 2s 14ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0902 - val_accuracy: 0.9780\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 2s 16ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.1399 - val_accuracy: 0.9700\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 2s 14ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.1625 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 2s 14ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.2503 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.1068 - val_accuracy: 0.9840\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 0.0633 - val_accuracy: 0.9840\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0594 - val_accuracy: 0.9860\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0679 - val_accuracy: 0.9880\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 2.0209e-04 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9880\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 5.2943e-05 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9880\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 4.0878e-05 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9880\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 3.3380e-05 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9880\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 2.8011e-05 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9880\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 2.4093e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9880\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 2.0936e-05 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# XAI를 수행하기 위해 사전 딥러닝 모델을 학습\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "loss_fn= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model= Sequential([\n",
    "    layers.Conv2D(32,(3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, shuffle =True, validation_data=(X_validation, Y_validation))\n",
    "\n",
    "model.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import saliency.core as saliency\n",
    "\n",
    "def model_fn(images, call_model_args, expected_keys=None):\n",
    "    target_class_idx= call_model_args['class']\n",
    "    model= call_model_args['model']\n",
    "    images=tf.convert_to_tensor(images)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        if expected_keys==[saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
    "            tape.watch(images)\n",
    "            output=model(images)\n",
    "            output=output[:, target_class_idx]\n",
    "            gradients =np.array(tape.gradient(output, images))\n",
    "            return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "        else:\n",
    "            conv, output=model(images)\n",
    "            gradients =np.array(tape.gradients(output, conv))\n",
    "            return {saliency.base.CONVOLUTION_LAYER_VALUES: conv,\n",
    "            saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_saliency(model, img):\n",
    "    pred = model(np.array([img]))\n",
    "    pred_cls =np.argmax(pred[0])\n",
    "    args ={'model': model, 'class': pred_cls}\n",
    "\n",
    "    grad=saliency.GradientSaliency()\n",
    "    attr =grad.GetMask(img, model_fn, args)\n",
    "    attr =  saliency.VisualizeImageGrayscale(attr)\n",
    "\n",
    "    return tf.reshape(attr, (*attr.shape,1))\n",
    "\n",
    "def ig(model, img):\n",
    "    pred= model(np.array([img]))\n",
    "    pred_cls =np.argmax(pred[0])\n",
    "    args={'model':model, 'class': pred_cls}\n",
    "\n",
    "    baseline =np.zeros(img.shape)\n",
    "    ig= saliency.IntegratedGradients()\n",
    "    attr= ig.GetMask(img, model_fn, args,x_steps=25, x_baseline=baseline, batch_size=20)\n",
    "    attr =saliency.VisualizeImageGrayscale(attr)\n",
    "\n",
    "    return tf.reshape(attr, (*attr.shape,1))\n",
    "\n",
    "def smooth_saliency(model, img):\n",
    "    pred = model(np.array([img]))\n",
    "    pred_cls = np.argmax(pred[0])\n",
    "    args = {'model': model, 'class': pred_cls}\n",
    "\n",
    "    smooth_grad = saliency.GradientSaliency()\n",
    "    smooth_attr = smooth_grad.GetSmoothedMask(img, model_fn, args)\n",
    "    smooth_attr = saliency.VisualizeImageGrayscale(smooth_attr)\n",
    "\n",
    "    return tf.reshape(smooth_attr, (*smooth_attr.shape, 1))\n",
    "\n",
    "def smooth_ig(model, img):\n",
    "\n",
    "    pred = model(np.array([img]))\n",
    "    pred_cls = np.argmax(pred[0])\n",
    "    args = {'model': model, 'class': pred_cls}\n",
    "\n",
    "    baseline = np.zeros(img.shape)\n",
    "    smooth_ig = saliency.IntegratedGradients()\n",
    "\n",
    "    smooth_attr = smooth_ig.GetSmoothedMask(\n",
    "        img, model_fn, args, x_steps=25, x_baseline=baseline, batch_size=20)\n",
    "\n",
    "    smooth_attr = saliency.VisualizeImageGrayscale(smooth_attr)\n",
    "\n",
    "    return tf.reshape(smooth_attr, (*smooth_attr.shape, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num =77\n",
    "sample_image= X_validation[data_num]\n",
    "sample_saliency_xai_image= vanilla_saliency(model, X_validation[data_num])\n",
    "sample_ig_xai_image =ig(model, X_validation[data_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.reshape(sample_image, (28, 28)))\n",
    "plt.title(\"origin image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.reshape(sample_saliency_xai_image, (28, 28)))\n",
    "plt.title(\"saliency image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.reshape(sample_ig_xai_image, (28, 28)))\n",
    "plt.title(\"ig image\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:30<00:00, 18.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ig_x_train = np.zeros_like(x_train)\n",
    "ig_x_test = np.zeros_like(x_test)\n",
    "\n",
    "for i in trange(len(ig_x_test)):\n",
    "\n",
    "    ig_x_train[i] = ig(model, x_train[i])\n",
    "    ig_x_test[i] = ig(model, x_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6499 - accuracy: 0.8018\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.1432 - accuracy: 0.9552\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0854 - accuracy: 0.9740\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0548 - accuracy: 0.9818\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0295 - accuracy: 0.9906\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0188 - accuracy: 0.9944\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0150 - accuracy: 0.9954\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 2.1720e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3097e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.0219e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 8.3248e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 6.9265e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 6.2558e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 5.0530e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b26304e8b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "new_model= Sequential([\n",
    "     layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPool2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "new_model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "new_model.fit(ig_x_train, y_train, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ig_x_test)):\n",
    "    data= np.expand_dims(ig_x_test[i],0)\n",
    "    pred= new_model.predict(data)\n",
    "    pred = np.argmax([pred])\n",
    "\n",
    "    submission['label'][i] =int(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4fd1451840babbb37e6226633a71627e1f918595ad990aa0f1a715d0e292c9f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
